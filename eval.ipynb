{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from layer import QRNNLayer\n",
    "from model import QRNNModel\n",
    "\n",
    "import data.data_utils as data_utils\n",
    "from data.data_utils import fopen\n",
    "from data.data_utils import load_inv_dict\n",
    "from data.data_utils import seq2words\n",
    "\n",
    "from data.data_iterator import TextIterator\n",
    "from data.data_iterator import BiTextIterator\n",
    "from data.data_iterator import prepare_batch\n",
    "from data.data_iterator import prepare_train_batch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading parameters\n",
    "src_vocab='data/train.en.json'\n",
    "tgt_vocab='data/train.de.json'\n",
    "# src_train='data/train.clean.en'\n",
    "# tgt_train='data/train.clean.fr'\n",
    "# src_valid='data/train.clean.en'\n",
    "# tgt_valid='data/train.clean.fr'\n",
    "src_train='data/test.en'\n",
    "tgt_train='data/test.de'\n",
    "src_valid='data/test.en'\n",
    "tgt_valid='data/test.de'\n",
    "\n",
    "# Network parameters\n",
    "kernel_size = 2\n",
    "hidden_size = 10\n",
    "num_layers = 2\n",
    "emb_size = 500\n",
    "num_enc_symbols = 30000\n",
    "num_dec_symbols = 30000\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Training parameters\n",
    "lr = 0.0002\n",
    "max_grad_norm = 1.0\n",
    "batch_size = 128\n",
    "max_epochs = 1000\n",
    "maxi_batches = 20\n",
    "max_seq_len = 18\n",
    "display_freq = 100\n",
    "save_freq = 100\n",
    "valid_freq = 100\n",
    "model_dir = 'model/'\n",
    "model_name = 'model.pkl'\n",
    "shuffle = True\n",
    "sort_by_len = True\n",
    "\n",
    "# Decoding parameters\n",
    "model_path = 'model/model.pkl'\n",
    "decode_input = 'data/test.en'\n",
    "decode_output = 'data/test.en.trans'\n",
    "max_decode_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    if os.path.exists(model_path):\n",
    "        print 'Reloading model parameters..'\n",
    "        checkpoint = torch.load(model_path)\n",
    "        model = QRNNModel(QRNNLayer, num_layers, kernel_size,\n",
    "                          hidden_size, emb_size, \n",
    "                          num_enc_symbols, num_dec_symbols)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    else:\n",
    "        raise ValueError('No such file:[{}]'.format(model_path))\n",
    "\n",
    "    return model, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model parameters..\n",
      "Using gpu..\n",
      "Decoding starts..\n",
      "source \n",
      "   31   170  1809     9   898    12   862    40    45  1112    98     3     3\n",
      "   14    30    38   138  2080   120  1619  2079   389  2078     3     3     3\n",
      " 1592     5    29   647     5    14   367    43   743     3     3     3     3\n",
      " 1961    25    18   326    15    42     5   146    36     3     3     3     3\n",
      " 1280     6     4   148  1942    68   943    10   931  1170     3     3     3\n",
      "  519    34    18   894    70     4   725     9  1555     3     3     3     3\n",
      " 1298  1184     5   171     5    15    16   862    40     3     3     3     3\n",
      "   14  1915  1925     4  1662     6     4    33    44  1920    17  1398  1387\n",
      "  519    21   892    12    96    17    16   353    10     4     3     3     3\n",
      " 1374     5    22    42    34    21   531     5     4     3     3     3     3\n",
      "  294     4   170  1626     5    14   139    69    22    29     3     3     3\n",
      "   83     4  2254     5    14    39    38     8  2249     3     3     3     3\n",
      "  146    36     5    17    12   121     6   150     7     3     3     3     3\n",
      "  146    36     5    17    12   121     6   150     7     3     3     3     3\n",
      " 3654     6     4  1662     3     3     3     3     3     3     3     3     3\n",
      "[torch.LongTensor of size 15x13]\n",
      "\n",
      "source_len \n",
      " 11\n",
      " 10\n",
      "  9\n",
      "  9\n",
      " 10\n",
      "  9\n",
      "  9\n",
      " 13\n",
      " 10\n",
      "  9\n",
      " 10\n",
      "  9\n",
      "  9\n",
      "  9\n",
      "  4\n",
      "[torch.LongTensor of size 15]\n",
      "\n",
      "dec_input \n",
      "    0    88    62    53  2151    34    11    46   988     5    82\n",
      "    0  2077    51   139    27  2078    11   240  2054    22     3\n",
      "    0  2059     4    28   538     4    16   301     4    12     3\n",
      "    0  2142    26  1958     4    75    51     4    58   113     3\n",
      "    0   414    10  2158     4     7    26     9  1920   210     3\n",
      "    0   228    51   993    87     6   923     8    29  2153     3\n",
      "    0    31   270    51     4    34    11    46   988    11     3\n",
      "    0    31  2107     7    94  1990     4    29  2110   859     3\n",
      "    0   410    53   517     6   557    69    46   151     3     3\n",
      "    0   228    51  1993   704     4    15     6  2123     3     3\n",
      "    0   253    20   302   102   757    15     4     3     3     3\n",
      "    0  2022    42    16    51   516    36    20     3     3     3\n",
      "    0    58   113     4    38   991     5     3     3     3     3\n",
      "    0    58   113     4    38   991     5     3     3     3     3\n",
      "    0  1635     6   864     3     3     3     3     3     3     3\n",
      "[torch.LongTensor of size 15x11]\n",
      "\n",
      "dec_target \n",
      "   88    62    53  2151    34    11    46   988     5    82     1\n",
      " 2077    51   139    27  2078    11   240  2054    22     1     3\n",
      " 2059     4    28   538     4    16   301     4    12     1     3\n",
      " 2142    26  1958     4    75    51     4    58   113     1     3\n",
      "  414    10  2158     4     7    26     9  1920   210     1     3\n",
      "  228    51   993    87     6   923     8    29  2153     1     3\n",
      "   31   270    51     4    34    11    46   988    11     1     3\n",
      "   31  2107     7    94  1990     4    29  2110   859     1     3\n",
      "  410    53   517     6   557    69    46   151     1     3     3\n",
      "  228    51  1993   704     4    15     6  2123     1     3     3\n",
      "  253    20   302   102   757    15     4     1     3     3     3\n",
      " 2022    42    16    51   516    36    20     1     3     3     3\n",
      "   58   113     4    38   991     5     1     3     3     3     3\n",
      "   58   113     4    38   991     5     1     3     3     3     3\n",
      " 1635     6   864     1     3     3     3     3     3     3     3\n",
      "[torch.LongTensor of size 15x11]\n",
      "\n",
      "dec_input\n",
      "Variable containing:\n",
      "-7.7168e+00  1.0065e+01 -1.1759e+01  ...  -7.1203e+00 -7.9967e+00 -5.8180e+00\n",
      "-1.2401e+01  9.8244e+00 -1.3173e+01  ...  -1.0485e+01 -1.1987e+01 -1.1940e+01\n",
      "-1.7222e+01  6.5410e+00 -1.2540e+01  ...  -1.6476e+01 -1.7378e+01 -1.7665e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.4526e+01  1.4758e+01 -1.3032e+01  ...  -1.0541e+01 -1.4990e+01 -1.7207e+01\n",
      "-1.2568e+01  9.9729e+00 -1.0031e+01  ...  -1.0139e+01 -1.1559e+01 -1.6724e+01\n",
      "-1.0906e+01  9.3775e+00 -1.2461e+01  ...  -1.1865e+01 -1.3091e+01 -1.3014e+01\n",
      "[torch.cuda.FloatTensor of size 165x30000 (GPU 0)]\n",
      "\n",
      "dec_input[:,:1]\n",
      "Variable containing:\n",
      " -9.0780   3.6305  -8.2049  ...   -9.7480 -12.7619  -9.8404\n",
      "-19.7273  13.8144 -17.6596  ...  -17.5411 -22.2215 -22.2943\n",
      "-20.1071  13.5402 -18.0861  ...  -18.3777 -22.4966 -22.4406\n",
      "           ...               ⋱              ...            \n",
      "-20.4644  14.0704 -17.2405  ...  -17.5902 -22.6965 -23.4663\n",
      "-20.4644  14.0704 -17.2405  ...  -17.5902 -22.6965 -23.4663\n",
      "-20.3270  14.6716 -17.2093  ...  -17.0901 -22.6933 -23.4944\n",
      "[torch.cuda.FloatTensor of size 15x30000 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, config = load_model()\n",
    "\n",
    "# Load source data to decode\n",
    "test_set = TextIterator(source=decode_input,\n",
    "                        source_dict=src_vocab,\n",
    "                        batch_size=batch_size,\n",
    "                        n_words_source=num_enc_symbols,\n",
    "                        maxlen=None)\n",
    "\n",
    "valid_set = BiTextIterator(source=src_valid,\n",
    "                           target=tgt_valid,\n",
    "                           source_dict=src_vocab,\n",
    "                           target_dict=tgt_vocab,\n",
    "                           batch_size=batch_size,\n",
    "                           maxlen=None,\n",
    "                           shuffle_each_epoch=False,\n",
    "                           n_words_source=num_enc_symbols,\n",
    "                           n_words_target=num_dec_symbols)\n",
    "\n",
    "target_inv_dict = load_inv_dict(tgt_vocab)\n",
    "\n",
    "if use_cuda:\n",
    "    print 'Using gpu..'\n",
    "    model = model.cuda()\n",
    "\n",
    "try:\n",
    "    print 'Decoding starts..'\n",
    "    fout = fopen(decode_output, 'w')\n",
    "    #for idx, source_seq in enumerate(test_set):\n",
    "    \n",
    "    for idx, (source_seq, target_seq) in enumerate(valid_set):\n",
    "        # source, source_len = prepare_batch(source_seq)\n",
    "        # Get a batch from training parallel data\n",
    "        source, source_len, dec_input, dec_target, dec_len = \\\n",
    "            prepare_train_batch(source_seq, target_seq, max_seq_len)\n",
    "        \n",
    "        print 'source', source\n",
    "        print 'source_len', source_len\n",
    "        print 'dec_input', dec_input\n",
    "        print 'dec_target', dec_target\n",
    "\n",
    "        preds_prev = torch.zeros(len(source), max_decode_step).long()\n",
    "        preds_prev[:,0] += data_utils.start_token\n",
    "        preds = torch.zeros(len(source), max_decode_step).long()\n",
    "\n",
    "        if use_cuda:\n",
    "            source = Variable(source.cuda())\n",
    "            source_len = Variable(source_len.cuda())\n",
    "            preds_prev = Variable(preds_prev.cuda())\n",
    "            preds = preds.cuda()\n",
    "            dec_input = Variable(dec_input.cuda())\n",
    "        else:\n",
    "            source = Variable(source)\n",
    "            source_len = Variable(source_len)\n",
    "            preds_prev = Variable(preds_prev)\n",
    "\n",
    "        states, memories = model.encode(source, source_len)\n",
    "        \n",
    "        print 'dec_input'\n",
    "        _, logits_ = model.decode(dec_input, states, memories)\n",
    "        print logits_\n",
    "        \n",
    "        print 'dec_input[:,:1]'\n",
    "        _, logits__ = model.decode(dec_input[:,:1], states, memories)\n",
    "        print logits__\n",
    "        \n",
    "        \n",
    "        \n",
    "#        print 'states', states\n",
    "#        print 'memories', memories\n",
    "        \n",
    "#         for t in xrange(max_decode_step):\n",
    "#             # logits: [batch_size x max_decode_step, tgt_vocab_size]\n",
    "#             #print 'preds_prev', preds_prev[:,:t+1]\n",
    "#             _, logits = model.decode(dec_input, states, memories)\n",
    "#             # outputs: [batch_size, max_decode_step]\n",
    "#             outputs = torch.max(logits, dim=1)[1].view(len(source), -1)\n",
    "#             print 'preds', outputs\n",
    "#             preds[:,t] = outputs[:,t].data\n",
    "#             if t < max_decode_step - 1:\n",
    "#                 preds_prev[:,t+1] = outputs[:,t]\n",
    "\n",
    "#         for i in xrange(len(preds)):\n",
    "#             fout.write(str(seq2words(preds[i], target_inv_dict)) + '\\n')\n",
    "#             fout.flush()\n",
    "\n",
    "#        print '  {}th line decoded'.format(idx * batch_size)\n",
    "#    print 'Decoding terminated'\n",
    "\n",
    "except IOError:\n",
    "    pass\n",
    "finally:\n",
    "    fout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
